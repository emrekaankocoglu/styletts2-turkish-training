# Turkish AuxiliaryASR Training Configuration (DDP)
#
# Use with:
#   torchrun --standalone --nproc_per_node 4 train_turkish_ddp.py -p ./Configs/config_turkish_ddp.yml
#
# Notes:
# - `batch_size` is PER-GPU.
# - `log_dir` is separate so it won't overwrite single-GPU checkpoints.

log_dir: "/home/ubuntu/styletts2-turkish-training/turkish_recipe/auxasr/Checkpoint_ddp"
save_freq: 10
device: "cuda"
epochs: 200
batch_size: 32
num_workers: 2

# Optional resume
pretrained_model: ""
load_only_params: true

train_data: "/home/ubuntu/styletts2-turkish-training/turkish_recipe/auxasr/Data/train_list_phonemized.txt"
val_data: "/home/ubuntu/styletts2-turkish-training/turkish_recipe/auxasr/Data/val_list_phonemized.txt"

preprocess_params:
  sr: 24000
  spect_params:
    n_fft: 2048
    win_length: 1200
    hop_length: 300
  mel_params:
    n_mels: 80

model_params:
   input_dim: 80
   hidden_dim: 256
   n_token: 116
   token_embedding_dim: 256

optimizer_params:
  lr: 0.0005
  pct_start: 0.0

